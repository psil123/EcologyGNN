{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "C6p7PnbuhRFv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5e7uMobTHOb"
      },
      "outputs": [],
      "source": [
        "!pip uninstall torch_geometric -y\n",
        "!pip install torch-scatter\n",
        "!pip install torch-sparse\n",
        "!pip install torch-cluster\n",
        "!pip install torch-spline-conv\n",
        "!pip install torch-geometric\n",
        "!pip install dgl\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-2.2.1+cu121.html\n",
        "!pip install torch_geometric\n",
        "!pip install torch-sparse\n",
        "!pip install pyg_lib\n",
        "import pyglib\n",
        "import torch_sparse\n",
        "import torch_geometric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxEjSkHC8fFj"
      },
      "source": [
        "# Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_cdH2Cw8fFj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# df1=pd.read_csv('SA02601_v6.csv')\n",
        "plant_feats=pd.read_csv('SA02602_v5.csv')[['PLOT_ID','PLTSP_CODE','NO_STALK','NO_FLWS']].iloc[1:]\n",
        "int_feats=pd.read_csv('SA02601_v6.csv')[['PLOT_ID','PLTSP_CODE','VISSP_CODE','VISSP_TYPE','VISSP_NO','NO_INT']]\n",
        "int_feats['PLTSP_CODE']=int_feats['PLTSP_CODE'].fillna(\"\").astype('string')\n",
        "int_feats=int_feats[int_feats['PLTSP_CODE']!='ALLIAMPL']\n",
        "\n",
        "plant_feats['PLTSP_CODE']=plant_feats['PLTSP_CODE'].fillna(\"\").astype('string')\n",
        "plant_feats=plant_feats[plant_feats['PLTSP_CODE']!='']\n",
        "plant_feats=plant_feats[~plant_feats['NO_FLWS'].isna()]\n",
        "plant_feats=plant_feats[~plant_feats['NO_STALK'].isna()]\n",
        "# plant_feats=plant_feats[plant_feats['PLTSP_CODE']!='ALLIAMPL']\n",
        "\n",
        "int_feats=int_feats[int_feats['PLTSP_CODE']!='']\n",
        "int_feats=int_feats[int_feats['PLTSP_CODE'].isin(list(plant_feats['PLTSP_CODE']))]\n",
        "# int_feats=int_feats[int_feats['PLTSP_CODE']!='']\n",
        "# data=data.rename({'PLTSP_NAME_x':'PLTSP_NAME'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xL75d6c2g9M9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6AOXuo7vgMA7"
      },
      "outputs": [],
      "source": [
        "visit_feats=int_feats[['VISSP_CODE','VISSP_TYPE']]\n",
        "int_feats=int_feats[['PLOT_ID','PLTSP_CODE','VISSP_CODE','VISSP_NO','NO_INT']]\n",
        "plant_feats=plant_feats.groupby('PLTSP_CODE')[['NO_STALK','NO_FLWS']].mean()\n",
        "plant_feats['PLTSP_CODE']=plant_feats.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvX4NCpmx25L"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "# CODE=LabelEncoder().fit(codes)\n",
        "PLTSP_CODE=LabelEncoder().fit(plant_feats['PLTSP_CODE'])\n",
        "VISSP_CODE=LabelEncoder().fit(visit_feats['VISSP_CODE'])\n",
        "VISSP_TYPE=LabelEncoder().fit(visit_feats['VISSP_TYPE'])\n",
        "PLOT_ID=LabelEncoder().fit(int_feats['PLOT_ID'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHlBK9-k-q8C"
      },
      "outputs": [],
      "source": [
        "plant_feats['PLTSP_CODE']=PLTSP_CODE.transform(plant_feats['PLTSP_CODE'])\n",
        "\n",
        "int_feats['PLTSP_CODE']=PLTSP_CODE.transform(int_feats['PLTSP_CODE'])\n",
        "int_feats['VISSP_CODE']=VISSP_CODE.transform(int_feats['VISSP_CODE'])\n",
        "int_feats['PLOT_ID']=PLOT_ID.transform(int_feats['PLOT_ID'])\n",
        "\n",
        "visit_feats['VISSP_CODE']=VISSP_CODE.transform(visit_feats['VISSP_CODE'])\n",
        "visit_feats['VISSP_TYPE']=VISSP_TYPE.transform(visit_feats['VISSP_TYPE'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6PPDsCs2p-K"
      },
      "outputs": [],
      "source": [
        "from sklearn.mixture import GaussianMixture\n",
        "temp=int_feats.groupby(['PLOT_ID','PLTSP_CODE','VISSP_CODE'])[['VISSP_NO','NO_INT']].mean()\n",
        "from scipy.special import comb\n",
        "def binom_pmf(N, k, p):\n",
        "    # Using gamma function to handle non-integer combinations in binomial coefficient\n",
        "    return comb(N, k) * (p**k) * ((1 - p)**(N - k))\n",
        "out=[]\n",
        "for N,k in zip(temp['VISSP_NO'],temp['NO_INT']):\n",
        "  if(N<=k):\n",
        "    out.append(binom_pmf(N,k,0.5))\n",
        "  else:\n",
        "    out.append(1)\n",
        "temp['EDGE_PROB']=out\n",
        "temp=temp[temp['EDGE_PROB']>0]\n",
        "# int_feats=temp[['PLOT_ID','PLTSP_CODE','EDGE_PROB']]\n",
        "temp['PLOT_ID']=[i for i,j,k in temp.index]\n",
        "temp['PLTSP_CODE']=[j for i,j,k in temp.index]\n",
        "temp['VISSP_CODE']=[k for i,j,k in temp.index]\n",
        "temp.index=range(1,len(temp.index)+1)\n",
        "temp=temp.drop(['NO_INT','VISSP_NO'],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_jiEyse8DzN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "gmm = GaussianMixture(n_components=3, random_state=42)\n",
        "interaction_data = np.array(temp['EDGE_PROB']).reshape(-1, 1)\n",
        "gmm.fit(interaction_data)\n",
        "\n",
        "def all_plot_prob(interaction_data):\n",
        "#   print(interaction_data)\n",
        "  responsibilities = gmm.predict_proba(np.array(interaction_data).reshape(-1,1))\n",
        "\n",
        "  reduced_edges = np.dot(responsibilities.T, np.array(interaction_data).reshape(-1,1)) / responsibilities.sum(axis=0)\n",
        "  reduced_edges[reduced_edges==np.inf]=0\n",
        "  reduced_edges=np.nan_to_num(reduced_edges)\n",
        "  return reduced_edges.T[0]\n",
        "# print(temp.groupby(['PLTSP_CODE','VISSP_CODE'])['EDGE_PROB'].mean())\n",
        "# edge_wt=pd.DataFrame(temp.groupby(['PLTSP_CODE','VISSP_CODE'])['EDGE_PROB'].mean())#.apply(all_plot_prob))\n",
        "edge_wt=pd.DataFrame(temp.groupby(['PLTSP_CODE','VISSP_CODE'])['EDGE_PROB'].apply(all_plot_prob))\n",
        "# edge_wt = edge_wt[edge_wt['EDGE_PROB'].apply(lambda x:sum(x)!=0)]\n",
        "edge_wt['PLTSP_CODE']=[j for j,k in edge_wt.index]\n",
        "edge_wt['VISSP_CODE']=[k for j,k in edge_wt.index]\n",
        "edge_wt.index=range(1,len(edge_wt.index)+1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5h5Vd70z8fFm"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.data import HeteroData\n",
        "import torch_geometric.transforms as T\n",
        "import torch\n",
        "import numpy as np\n",
        "data = HeteroData()# Save node indices:\n",
        "data[\"plant\"].node_id = torch.arange(len(PLTSP_CODE.classes_)).long()\n",
        "data[\"visitor\"].node_id = torch.arange(len(VISSP_CODE.classes_)).long()# Add the node features and edge indices:\n",
        "# vals=train.values.tolist()\n",
        "# vals.extend(test.values.tolist())\n",
        "# nfeats_p={i[0]:[i[-1],i[-2]] for i in vals}\n",
        "# nfeats_i={i[1]:[i[2],i[2]] for i in vals}\n",
        "temp=[]\n",
        "for i in range(len(PLTSP_CODE.classes_)):\n",
        "  data1=plant_feats[plant_feats['PLTSP_CODE']==i]\n",
        "  temp.append([float(data1['NO_STALK']),float(data1['NO_FLWS'])])\n",
        "data[\"plant\"].x = torch.Tensor(temp)\n",
        "\n",
        "temp=[]\n",
        "for i in range(len(VISSP_CODE.classes_)):\n",
        "  data1=visit_feats[visit_feats['VISSP_CODE']==i].to_numpy()[0]\n",
        "  temp.append([data1[1]/len(VISSP_CODE.classes_)])\n",
        "data[\"visitor\"].x = torch.Tensor(temp).float()\n",
        "\n",
        "train_edge1=list(set(zip(list(edge_wt['VISSP_CODE']),list(edge_wt['PLTSP_CODE']))))\n",
        "# train_edge2=[(v,u) for u,v in train_edge1]\n",
        "# train_edge2.extend(train_edge1)\n",
        "train_edge=[[u for u,v in train_edge1],[v for u,v in train_edge1]]\n",
        "data[\"visitor\", \"visits\", \"plant\"].edge_index = torch.Tensor(train_edge).long()\n",
        "data[\"visitor\", \"visits\", \"plant\"].edge_attr = torch.Tensor(np.array(list(edge_wt['EDGE_PROB']))).float()# We also need to make sure to add the reverse edges from movies to users\n",
        "# # in order to let a GNN be able to pass messages in both directions.\n",
        "# # We can leverage the `T.ToUndirected()` transform for this from PyG:\n",
        "data = T.ToUndirected()(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0VEoqBwmDWL"
      },
      "source": [
        "# GNN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2pP4Hvh7maG3"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.loader import LinkNeighborLoader\n",
        "transform = T.RandomLinkSplit(\n",
        "#     num_val=0.1,\n",
        "#     num_test=0.1,\n",
        "#     disjoint_train_ratio=0.3,\n",
        "    neg_sampling_ratio=1.0,\n",
        "    add_negative_train_samples=True,\n",
        "    edge_types=(\"visitor\", \"visits\", \"plant\"),\n",
        "    rev_edge_types=(\"plant\", \"rev_visits\", \"visitor\"),\n",
        ")\n",
        "train_data, val_data, test_data = transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SfAyq1Zbg9NA"
      },
      "outputs": [],
      "source": [
        "edge_label_index = train_data[\"visitor\", \"visits\", \"plant\"].edge_label_index\n",
        "edge_label = train_data[\"visitor\", \"visits\", \"plant\"].edge_label\n",
        "train_loader = LinkNeighborLoader(\n",
        "    data=train_data,\n",
        "    num_neighbors=[5, 2],\n",
        "#     neg_sampling_ratio=2.0,\n",
        "    edge_label_index=((\"visitor\", \"visits\", \"plant\"), edge_label_index),\n",
        "    edge_label=edge_label,\n",
        "    batch_size=128,\n",
        "    shuffle=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CV0Ijj8ug9NA"
      },
      "outputs": [],
      "source": [
        "edge_label_index = val_data[\"visitor\", \"visits\", \"plant\"].edge_label_index\n",
        "edge_label = val_data[\"visitor\", \"visits\", \"plant\"].edge_label\n",
        "val_loader = LinkNeighborLoader(\n",
        "    data=val_data,\n",
        "    num_neighbors=[5, 2],\n",
        "#     neg_sampling_ratio=2.0,\n",
        "    edge_label_index=((\"visitor\", \"visits\", \"plant\"), edge_label_index),\n",
        "    edge_label=edge_label,\n",
        "    batch_size=128,\n",
        "    shuffle=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S72Xyx66g9NA"
      },
      "outputs": [],
      "source": [
        "edge_label_index = test_data[\"visitor\", \"visits\", \"plant\"].edge_label_index\n",
        "edge_label = test_data[\"visitor\", \"visits\", \"plant\"].edge_label\n",
        "test_loader = LinkNeighborLoader(\n",
        "    data=test_data,\n",
        "    num_neighbors=[5, 2],\n",
        "#     neg_sampling_ratio=2.0,\n",
        "    edge_label_index=((\"visitor\", \"visits\", \"plant\"), edge_label_index),\n",
        "    edge_label=edge_label,\n",
        "    batch_size=128,\n",
        "    shuffle=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Mw6q__xpfJm"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn import SAGEConv, to_hetero\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torch import Tensor\n",
        "class GNN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
        "    def forward(self, x: Tensor, edge_index: Tensor) -> Tensor:\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.leaky_relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "# Our final classifier applies the dot-product between source and destination\n",
        "# node embeddings to derive edge-level predictions:\n",
        "class Classifier(torch.nn.Module):\n",
        "    def forward(self, x_visitor: Tensor, x_plant: Tensor, edge_label_index: Tensor) -> Tensor:\n",
        "        # Convert node embeddings to edge-level representations:\n",
        "        edge_feat_visitor = x_visitor[edge_label_index[0]]\n",
        "        edge_feat_plant = x_plant[edge_label_index[1]]\n",
        "        # Apply dot-product to get a prediction per supervision edge:\n",
        "        return (edge_feat_visitor * edge_feat_plant).sum(dim=-1)\n",
        "\n",
        "class EdgeClassifier(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels,embedding_size):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(embedding_size*2, hidden_channels)\n",
        "\n",
        "        # Non-linearity\n",
        "        self.sigmoid1 = nn.Sigmoid()\n",
        "\n",
        "        # Linear function (readout)\n",
        "#         self.fc2 = nn.Linear(128, 128)\n",
        "#         self.sigmoid2 = nn.Sigmoid()\n",
        "        self.fc3 = nn.Linear(hidden_channels, 3)\n",
        "\n",
        "    def forward(self, x_visitor: Tensor, x_plant: Tensor, edge_label_index: Tensor) -> Tensor:\n",
        "        # Convert node embeddings to edge-level representations:\n",
        "        edge_feat_visitor = x_visitor[edge_label_index[0]]\n",
        "        edge_feat_plant = x_plant[edge_label_index[1]]\n",
        "#         print(edge_feat_visitor.shape,edge_feat_plant.shape,.shape)\n",
        "        edge_feats=torch.cat((edge_feat_visitor,edge_feat_plant),1)\n",
        "#         print(edge_feats.shape)\n",
        "        x=self.fc1(edge_feats)\n",
        "        x=self.sigmoid1(x)\n",
        "#         x=self.fc2(x)\n",
        "#         x=self.sigmoid2(x)\n",
        "        x=self.fc3(x)\n",
        "        return x\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels,embedding_size):\n",
        "        super().__init__()\n",
        "        # Since the dataset does not come with rich features, we also learn two\n",
        "        # embedding matrices for users and movies:\n",
        "        self.plant_lin = torch.nn.Linear(2, embedding_size)\n",
        "        self.visitor_lin = torch.nn.Linear(1, embedding_size)\n",
        "        self.visitor_emb = torch.nn.Embedding(data[\"visitor\"].num_nodes, embedding_size)\n",
        "        self.plant_emb = torch.nn.Embedding(data[\"plant\"].num_nodes, embedding_size)\n",
        "        # Instantiate homogeneous GNN:\n",
        "        self.gnn = GNN(embedding_size)\n",
        "        # Convert GNN model into a heterogeneous variant:\n",
        "        self.gnn = to_hetero(self.gnn, metadata=data.metadata())\n",
        "        self.classifier = Classifier()\n",
        "        self.edgeclassifier = EdgeClassifier(hidden_channels,embedding_size)\n",
        "    def forward(self, data: HeteroData) -> Tensor:\n",
        "        x_dict = {\n",
        "          \"visitor\": self.visitor_emb(data[\"visitor\"].node_id)+ self.visitor_lin(data[\"visitor\"].x.float()),\n",
        "          \"plant\": self.plant_lin(data[\"plant\"].x) + self.plant_emb(data[\"plant\"].node_id),\n",
        "        }\n",
        "        # `x_dict` holds feature matrices of all node types\n",
        "        # `edge_index_dict` holds all edge indices of all edge types\n",
        "#         print(x_dict)\n",
        "        x_dict = self.gnn(x_dict, data.edge_index_dict)\n",
        "#         print(x_dict)\n",
        "        pred2 = self.edgeclassifier(\n",
        "            x_dict[\"visitor\"],\n",
        "            x_dict[\"plant\"],\n",
        "            data[\"visitor\", \"visits\", \"plant\"].edge_label_index,\n",
        "        )\n",
        "        pred = self.classifier(\n",
        "            x_dict[\"visitor\"],\n",
        "            x_dict[\"plant\"],\n",
        "            data[\"visitor\", \"visits\", \"plant\"].edge_label_index,\n",
        "        )\n",
        "#         print(pred)\n",
        "        return pred,pred2\n",
        "\n",
        "model = Model(hidden_channels=64,embedding_size=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q690o5pGqVec"
      },
      "outputs": [],
      "source": [
        "import tqdm\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import MSELoss\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device: '{device}'\")\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "train_loss=[]\n",
        "val_loss=[]\n",
        "for epoch in range(1, 100):\n",
        "    total_loss = total_examples = 0\n",
        "    for sampled_data in tqdm.tqdm(train_loader):\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        sampled_data.to(device)\n",
        "        pred,pred2 = model(sampled_data)\n",
        "#         print(pred2)\n",
        "#         pred=torch.nan_to_num(pred)\n",
        "#         print(sampled_data)\n",
        "\n",
        "        ground_truth_1 = sampled_data[\"visitor\", \"visits\", \"plant\"].edge_label.float()\n",
        "        ground_truth_2 = sampled_data[\"visitor\", \"visits\", \"plant\"].edge_attr\n",
        "#         print(max(sampled_data[\"visitor\", \"visits\", \"plant\"].edge_label_index[0]),max(sampled_data[\"visitor\", \"visits\", \"plant\"].edge_label_index[1]))\n",
        "#         print(max(sampled_data[\"visitor\", \"visits\", \"plant\"].edge_index[0]),max(sampled_data[\"visitor\", \"visits\", \"plant\"].edge_index[1]))\n",
        "        L1 = F.binary_cross_entropy_with_logits(pred, ground_truth_1)\n",
        "        temp=[]\n",
        "#         print(sampled_data[\"visitor\", \"visits\", \"plant\"].edge_index,sampled_data[\"visitor\", \"visits\", \"plant\"].edge_label_index)\n",
        "\n",
        "        for u,v in zip(sampled_data[\"visitor\", \"visits\", \"plant\"].edge_label_index[0],sampled_data[\"visitor\", \"visits\", \"plant\"].edge_label_index[1]):\n",
        "                flag=True\n",
        "                for ind,uv in enumerate(zip(sampled_data[\"visitor\", \"visits\", \"plant\"].edge_index[0],sampled_data[\"visitor\", \"visits\", \"plant\"].edge_index[1])):\n",
        "                    u1,v1=uv\n",
        "                    if(u1==u and v1==v):\n",
        "                        temp.append(ground_truth_2[ind].tolist())\n",
        "                        flag=False\n",
        "                        break\n",
        "                if(flag):\n",
        "                    temp.append([0.0,0.0,0.0])\n",
        "\n",
        "#         print(ind1)\n",
        "        ground_truth_2=torch.Tensor(temp)\n",
        "#         print(ground_truth_1.shape,ground_truth_2.shape)\n",
        "#         print(pred.shape,pred2.shape)\n",
        "        L2 = F.mse_loss(pred2, ground_truth_2)\n",
        "        loss=L1+L2\n",
        "        train_loss.append(loss)\n",
        "#         VAL LOSS\n",
        "\n",
        "\n",
        "#         loss = MSELoss(pred, ground_truth)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += float(loss) * pred.numel()\n",
        "        total_examples += pred.numel()\n",
        "#         break\n",
        "    total_loss_val = total_examples_val = 0\n",
        "    for sampled_data in tqdm.tqdm(val_loader):\n",
        "        pred,pred2 = model(sampled_data)\n",
        "        ground_truth_1 = sampled_data[\"visitor\", \"visits\", \"plant\"].edge_label.float()\n",
        "        ground_truth_2 = sampled_data[\"visitor\", \"visits\", \"plant\"].edge_attr\n",
        "        L1 = F.binary_cross_entropy_with_logits(pred, ground_truth_1)\n",
        "        temp=[]\n",
        "        for u,v in zip(sampled_data[\"visitor\", \"visits\", \"plant\"].edge_label_index[0],sampled_data[\"visitor\", \"visits\", \"plant\"].edge_label_index[1]):\n",
        "                flag=True\n",
        "                for ind,uv in enumerate(zip(sampled_data[\"visitor\", \"visits\", \"plant\"].edge_index[0],sampled_data[\"visitor\", \"visits\", \"plant\"].edge_index[1])):\n",
        "                    u1,v1=uv\n",
        "                    if(u1==u and v1==v):\n",
        "                        temp.append(ground_truth_2[ind].tolist())\n",
        "                        flag=False\n",
        "                        break\n",
        "                if(flag):\n",
        "                    temp.append([0.0,0.0,0.0])\n",
        "        ground_truth_2=torch.Tensor(temp)\n",
        "        L2 = F.mse_loss(pred2, ground_truth_2)\n",
        "        loss=L1+L2\n",
        "        total_loss_val += float(loss) * pred.numel()\n",
        "        total_examples_val += pred.numel()\n",
        "#         VAL LOSS\n",
        "        val_loss.append(total_loss_val/total_examples_val)\n",
        "    torch.save(model.state_dict(), '/home/arka/Downloads/GNN/checkpoints/model_'+str(epoch+1)+'.pth')\n",
        "    print(f\"Epoch: {epoch:03d}, Loss: {total_loss / total_examples:.4f}, Val Loss: {total_loss_val/total_examples_val:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxIYMD3rg9NC",
        "outputId": "39b64936-ad61-4850-d214-8565013119b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define the validation seed edges:\n",
        "# torch.save(model.state_dict(), '/home/arka/Downloads/GNN/model_100_3.pth')\n",
        "model.load_state_dict(torch.load('/home/arka/Downloads/GNN/checkpoints/model_100_64_2.pth'))\n",
        "# import matplotlib.pyplot as plt\n",
        "# train_loss=[i.detach().numpy() for i in train_loss]\n",
        "# val_loss=[i.detach().numpy() for i in val_loss]\n",
        "# plt.plot(np.array(train_loss))\n",
        "# plt.plot(np.array(val_loss))\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "0mf0KS66g9ND"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np\n",
        "import tqdm\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import MSELoss\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device: '{device}'\")\n",
        "model = model.to(device)\n",
        "preds = []\n",
        "ground_truths = []\n",
        "print(len(test_loader))\n",
        "for sampled_data in tqdm.tqdm(test_loader):\n",
        "    with torch.no_grad():\n",
        "        sampled_data.to(device)\n",
        "#         print(sampled_data[\"visitor\",'visits','plant'].edge_label)\n",
        "        preds.append(model(sampled_data)[0])\n",
        "        ground_truths.append(sampled_data[\"visitor\",'visits','plant'].edge_label)\n",
        "pred = torch.cat(preds, dim=0).cpu().numpy()\n",
        "print(pred.shape)\n",
        "ground_truth = torch.cat(ground_truths, dim=0).cpu().numpy()\n",
        "pred=np.nan_to_num(pred)\n",
        "temp=pred\n",
        "temp=[0 if i <0 else 1 for i in temp]\n",
        "pred=temp\n",
        "print(ground_truth)\n",
        "cm = confusion_matrix(ground_truth, pred)\n",
        "ConfusionMatrixDisplay(cm).plot()\n",
        "auc = roc_auc_score(ground_truth, pred)\n",
        "print()\n",
        "print(f\"Validation AUC: {auc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFczDjL7g9ND"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np\n",
        "val_loader=test_loader\n",
        "preds = []\n",
        "ground_truths = []\n",
        "MSE=0\n",
        "for sampled_data in tqdm.tqdm(test_loader):\n",
        "    with torch.no_grad():\n",
        "        sampled_data.to(device)\n",
        "#         print(sampled_data)\n",
        "        pred,pred2 = model(sampled_data)\n",
        "        ground_truth_1 = sampled_data[\"visitor\", \"visits\", \"plant\"].edge_label.float()\n",
        "        ground_truth_2 = sampled_data[\"visitor\", \"visits\", \"plant\"].edge_attr\n",
        "        preds.append(pred)\n",
        "        ground_truths.append(sampled_data[\"visitor\",'visits','plant'].edge_label)\n",
        "        temp=[]\n",
        "\n",
        "        for u,v in zip(sampled_data[\"visitor\", \"visits\", \"plant\"].edge_label_index[0],sampled_data[\"visitor\", \"visits\", \"plant\"].edge_label_index[1]):\n",
        "                flag=True\n",
        "                for ind,uv in enumerate(zip(sampled_data[\"visitor\", \"visits\", \"plant\"].edge_index[0],sampled_data[\"visitor\", \"visits\", \"plant\"].edge_index[1])):\n",
        "                    u1,v1=uv\n",
        "                    if(u1==u and v1==v):\n",
        "                        temp.append(ground_truth_2[ind].tolist())\n",
        "                        flag=False\n",
        "                        break\n",
        "                if(flag):\n",
        "                    temp.append([0.0,0.0,0.0])\n",
        "\n",
        "        ground_truth_2=torch.Tensor(temp)\n",
        "        L2 = F.mse_loss(pred2, ground_truth_2)\n",
        "        MSE+=L2\n",
        "pred = preds[0]\n",
        "ground_truth = ground_truths[0]\n",
        "# !pip install torcheval\n",
        "# print(ground_truth,pred)\n",
        "# from torcheval.metrics import MulticlassAccuracy\n",
        "# auc=MulticlassAccuracy()\n",
        "# auc.update(torch.Tensor(ground_truth), torch.Tensor(pred))\n",
        "# print(auc.compute())\n",
        "# auc = roc_auc_score(ground_truth, pred)\n",
        "print()\n",
        "print(\"MSE : \",MSE)\n",
        "print(f\"Validation AUC: {auc:.4f}\")\n",
        "# print(preds[0].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEh_Fuq0mDUE"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}